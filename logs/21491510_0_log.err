[2024-10-07 23:21:23,848] torch.distributed.run: [WARNING] 
[2024-10-07 23:21:23,848] torch.distributed.run: [WARNING] *****************************************
[2024-10-07 23:21:23,848] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-10-07 23:21:23,848] torch.distributed.run: [WARNING] *****************************************
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Traceback (most recent call last):
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 88, in <module>
    init_process(run, args["embedding_dir"], args["data_dir"])
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 79, in init_process
    fn(dataloader, embedding_dir, model)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 25, in run
    embedding = model(im)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 325, in forward
    ret = self.forward_features(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 258, in forward_features
    x = self.prepare_tokens_with_masks(x, masks)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 215, in prepare_tokens_with_masks
    x = self.patch_embed(x)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/patch_embed.py", line 75, in forward
    x = self.proj(x)  # B C H W
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__cudnn_convolution)
Traceback (most recent call last):
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 88, in <module>
    init_process(run, args["embedding_dir"], args["data_dir"])
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 79, in init_process
    fn(dataloader, embedding_dir, model)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 25, in run
    embedding = model(im)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 325, in forward
    ret = self.forward_features(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 258, in forward_features
    x = self.prepare_tokens_with_masks(x, masks)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 215, in prepare_tokens_with_masks
    x = self.patch_embed(x)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/patch_embed.py", line 75, in forward
    x = self.proj(x)  # B C H W
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__cudnn_convolution)
Traceback (most recent call last):
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 88, in <module>
    init_process(run, args["embedding_dir"], args["data_dir"])
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 79, in init_process
    fn(dataloader, embedding_dir, model)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 25, in run
    embedding = model(im)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 325, in forward
    ret = self.forward_features(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 258, in forward_features
    x = self.prepare_tokens_with_masks(x, masks)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 215, in prepare_tokens_with_masks
    x = self.patch_embed(x)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/patch_embed.py", line 75, in forward
    x = self.proj(x)  # B C H W
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:2 and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__cudnn_convolution)
[2024-10-07 23:22:48,942] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 46341 closing signal SIGTERM
[2024-10-07 23:22:52,911] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 1 (pid: 46342) of binary: /home/jroth/.conda/envs/mct/bin/python
Traceback (most recent call last):
  File "/home/jroth/.conda/envs/mct/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
distributed_process.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-10-07_23:22:48
  host      : c830.oscer.ou.edu
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 46343)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-10-07_23:22:48
  host      : c830.oscer.ou.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 46344)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-10-07_23:22:48
  host      : c830.oscer.ou.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 46342)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
