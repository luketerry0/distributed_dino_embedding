[W socket.cpp:436] [c10d] The server socket has failed to bind to [::]:29501 (errno: 98 - Address already in use).
[W socket.cpp:436] [c10d] The server socket has failed to bind to 0.0.0.0:29501 (errno: 98 - Address already in use).
[E socket.cpp:472] [c10d] The server socket has failed to listen on any local network address.
Process Process-1:
Traceback (most recent call last):
  File "/home/jroth/.conda/envs/mct/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/jroth/.conda/envs/mct/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 66, in init_process
    dist.init_process_group(backend, rank=rank, world_size=size)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1141, in init_process_group
    store, rank, world_size = next(rendezvous_iterator)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 241, in _env_rendezvous_handler
    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/distributed/rendezvous.py", line 172, in _create_c10d_store
    return TCPStore(
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29501 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:29501 (errno: 98 - Address already in use).
Downloading: "https://github.com/facebookresearch/dinov2/zipball/main" to /home/luketerry/.cache/torch/hub/main.zip
Downloading: "https://github.com/facebookresearch/dinov2/zipball/main" to /home/luketerry/.cache/torch/hub/main.zip
Downloading: "https://github.com/facebookresearch/dinov2/zipball/main" to /home/luketerry/.cache/torch/hub/main.zip
Process Process-2:
Process Process-2:
Traceback (most recent call last):
  File "/home/jroth/.conda/envs/mct/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/jroth/.conda/envs/mct/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 69, in init_process
    fn(rank, size, dataloader, embedding_dir)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 19, in run
    model = dino_model(rank)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 36, in dino_model
    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14_reg', verbose=False)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/hub.py", line 563, in load
    repo_or_dir = _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, "load",
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/hub.py", line 262, in _get_cache_or_reload
    cached_zipfile.extractall(hub_dir)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/zipfile.py", line 1647, in extractall
    self._extract_member(zipinfo, path, pwd)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/zipfile.py", line 1697, in _extract_member
    os.mkdir(targetpath)
FileExistsError: [Errno 17] File exists: '/home/luketerry/.cache/torch/hub/facebookresearch-dinov2-e1277af'
Traceback (most recent call last):
  File "/home/jroth/.conda/envs/mct/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/jroth/.conda/envs/mct/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 69, in init_process
    fn(rank, size, dataloader, embedding_dir)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 19, in run
    model = dino_model(rank)
  File "/home/luketerry/distributed_dino_embedding/distributed_process.py", line 36, in dino_model
    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14_reg', verbose=False)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/hub.py", line 563, in load
    repo_or_dir = _get_cache_or_reload(repo_or_dir, force_reload, trust_repo, "load",
  File "/home/jroth/.conda/envs/mct/lib/python3.10/site-packages/torch/hub.py", line 262, in _get_cache_or_reload
    cached_zipfile.extractall(hub_dir)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/zipfile.py", line 1647, in extractall
    self._extract_member(zipinfo, path, pwd)
  File "/home/jroth/.conda/envs/mct/lib/python3.10/zipfile.py", line 1697, in _extract_member
    os.mkdir(targetpath)
FileExistsError: [Errno 17] File exists: '/home/luketerry/.cache/torch/hub/facebookresearch-dinov2-e1277af'
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/home/luketerry/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Downloading: "https://dl.fbaipublicfiles.com/dinov2/dinov2_vitb14/dinov2_vitb14_reg4_pretrain.pth" to /home/luketerry/.cache/torch/hub/checkpoints/dinov2_vitb14_reg4_pretrain.pth
  0%|          | 0.00/330M [00:00<?, ?B/s]  1%|          | 3.25M/330M [00:00<00:10, 33.9MB/s]  3%|▎         | 8.55M/330M [00:00<00:07, 46.6MB/s]  5%|▍         | 15.3M/330M [00:00<00:05, 56.5MB/s]  7%|▋         | 24.4M/330M [00:00<00:04, 71.5MB/s] 10%|█         | 34.6M/330M [00:00<00:03, 84.2MB/s] 14%|█▍        | 45.5M/330M [00:00<00:03, 94.4MB/s] 17%|█▋        | 56.3M/330M [00:00<00:02, 100MB/s]  20%|██        | 67.2M/330M [00:00<00:02, 105MB/s] 23%|██▎       | 77.2M/330M [00:00<00:02, 103MB/s] 27%|██▋       | 89.2M/330M [00:01<00:02, 110MB/s] 30%|███       | 100M/330M [00:01<00:02, 111MB/s]  34%|███▎      | 111M/330M [00:01<00:02, 112MB/s] 37%|███▋      | 122M/330M [00:01<00:01, 113MB/s] 40%|████      | 133M/330M [00:01<00:01, 113MB/s] 43%|████▎     | 143M/330M [00:01<00:01, 110MB/s] 47%|████▋     | 155M/330M [00:01<00:01, 113MB/s] 50%|█████     | 166M/330M [00:01<00:01, 113MB/s] 54%|█████▎    | 177M/330M [00:01<00:01, 113MB/s] 57%|█████▋    | 188M/330M [00:01<00:01, 113MB/s] 60%|██████    | 198M/330M [00:02<00:01, 110MB/s] 64%|██████▎   | 210M/330M [00:02<00:01, 114MB/s] 67%|██████▋   | 221M/330M [00:02<00:01, 114MB/s] 70%|███████   | 232M/330M [00:02<00:00, 114MB/s] 74%|███████▎  | 243M/330M [00:02<00:00, 114MB/s] 77%|███████▋  | 254M/330M [00:02<00:00, 114MB/s] 80%|████████  | 265M/330M [00:02<00:00, 111MB/s] 83%|████████▎ | 275M/330M [00:02<00:00, 111MB/s] 87%|████████▋ | 286M/330M [00:02<00:00, 112MB/s] 90%|████████▉ | 297M/330M [00:02<00:00, 113MB/s] 93%|█████████▎| 308M/330M [00:03<00:00, 113MB/s] 97%|█████████▋| 319M/330M [00:03<00:00, 110MB/s]100%|██████████| 330M/330M [00:03<00:00, 107MB/s]
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
slurmstepd: error: *** STEP 21409583.0 ON c830 CANCELLED AT 2024-10-02T21:42:30 ***
slurmstepd: error: *** JOB 21409583 ON c830 CANCELLED AT 2024-10-02T21:42:30 ***
